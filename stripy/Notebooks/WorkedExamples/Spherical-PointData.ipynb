{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked Example - Global Temperature Gradient Data\n",
    "\n",
    "In this notebook we read in the global heat flow data available through XXXX and explore a number of different stragegies for\n",
    "building useful triangulations to help process this data.\n",
    "\n",
    "The heat flow measurements in this database are globally sparse but contain regional surveys where the density of points is very much higher than average. In some of the regional surveys, data have been obtained along transects or have been processed into evenly spaced grid points. \n",
    "We will build the following different triangulations\n",
    "\n",
    "  - A naive triangulation of the given points \n",
    "  - A triangulation constructed by subdivision so that no point has more than a certain number of 'nearby' points from the dataset\n",
    "  - A triangulation constructed by subdivision so that no triangle contains more than a certain number of data points\n",
    "  - A triangulation in which points are removed if they are not the nearest point to any data point (a post-processing of the above hierarchical triangulations)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/usr/local/lib/python3.7/site-packages/osgeo/_gdal.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/proj/lib/libproj.15.dylib\n  Referenced from: /usr/local/Cellar/gdal/2.4.1/lib/libgdal.20.dylib\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47de13bdebcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstripy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstripy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gdal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import osgeo.gdal as a convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mosgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecation_warn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdeprecation_warn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mosgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/osgeo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0m_gdal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/osgeo/__init__.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_gdal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    340\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/usr/local/lib/python3.7/site-packages/osgeo/_gdal.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/proj/lib/libproj.15.dylib\n  Referenced from: /usr/local/Cellar/gdal/2.4.1/lib/libgdal.20.dylib\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "\n",
    "import os.path as path\n",
    "import stripy as stripy\n",
    "import numpy as np\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtiff = gdal.Open(\"/Users/lmoresi/Dropbox/+Research/Publications/MyPapers/CooperMiller-ContinentalStructure/Data/ETOPO1_Ice_g_geotiff.tif\")\n",
    "\n",
    "width = gtiff.RasterXSize\n",
    "height = gtiff.RasterYSize\n",
    "gt = gtiff.GetGeoTransform()\n",
    "img = gtiff.GetRasterBand(1).ReadAsArray().T\n",
    "\n",
    "img = np.fliplr(img)\n",
    "\n",
    "imgLR = img[::10,::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid0 = stripy.spherical_meshes.icosahedral_mesh(include_face_points=False, refinement_levels=0)\n",
    "grid3 = stripy.spherical_meshes.icosahedral_mesh(include_face_points=False, refinement_levels=3)\n",
    "gridR = stripy.spherical_meshes.icosahedral_mesh(include_face_points=False, refinement_levels=8)\n",
    "\n",
    "print grid0.npoints, grid3.npoints, gridR.npoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlons = np.mod(np.degrees(gridR.lons)+180.0, 360.0)\n",
    "dlats = np.mod(np.degrees(gridR.lats)+90, 180.0)\n",
    "\n",
    "ilons = img.shape[0] * dlons / 360.0\n",
    "ilats = img.shape[1] * dlats / 180.0\n",
    "\n",
    "icoords = np.stack((ilons, ilats))\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "meshheights = ndimage.map_coordinates(img, icoords , order=3, mode='nearest').astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datafile = \"/Users/lmoresi/Dropbox/+Research/Publications/MyPapers/CooperMiller-ContinentalStructure/Data/te_dat.xyte.txt\"\n",
    "\n",
    "datafile = \"../Data/HeatFlowGlobal2010.csv\"\n",
    "hf_data = np.genfromtxt(datafile, delimiter=\",\", comments=None, skip_header=1, missing_values=0.0, filling_values=0.0, invalid_raise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = hf_data[:,0]\n",
    "lo = hf_data[:,1]\n",
    "dT = hf_data[:,6] \n",
    "\n",
    "valid = np.logical_and(dT > 0.0, dT < 100.0)\n",
    "\n",
    "lats = la[valid]\n",
    "lons = lo[valid]\n",
    "data = dT[valid]\n",
    "\n",
    "lons = lons + np.random.random(lons.shape)*.00001\n",
    "lats = lats + np.random.random(lons.shape)*.00001\n",
    "lons = lons%360.0 # -180.0\n",
    "\n",
    "data_xyz = np.array( stripy.spherical.lonlat2xyz(np.radians(lons), np.radians(lats))).T\n",
    "\n",
    "print \"Valid data points:\", data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive meshing of the data points\n",
    "\n",
    "datagrid = stripy.sTriangulation(np.radians(lons), np.radians(lats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Robinson(central_longitude=0.0, globe=None))\n",
    "ax.coastlines(color=\"lightgrey\")\n",
    "ax.set_global()\n",
    "\n",
    "ax.scatter(lons, lats, c=data, cmap=plt.cm.RdBu_r,\n",
    "            marker=\"o\", s=10.0, transform=ccrs.Geodetic())\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lavavu\n",
    "\n",
    "striangulationR = gridR\n",
    "striangulation0 = grid3\n",
    "\n",
    "wireframeI = striangulationR\n",
    "trianglesI = striangulationR\n",
    "\n",
    "\n",
    "\n",
    "lv = lavavu.Viewer(border=False, background=\"#FFFFFF\", resolution=[2000,1000], near=-10.0)\n",
    "\n",
    "# Core \n",
    "\n",
    "tris = lv.triangles(\"LAB\",  wireframe=False, colour=\"#999999\", opacity=1.0)\n",
    "tris.vertices(striangulation0.points * 0.95 )\n",
    "tris.indices(striangulation0.simplices)\n",
    "\n",
    "tris3 = lv.triangles(\"datagrid\",  wireframe=False, colour=\"#77ff88\", opacity=1.0)\n",
    "tris3.vertices(datagrid.points)\n",
    "tris3.indices(datagrid.simplices)\n",
    "tris3.values(data)\n",
    "tris3.colourmap([\"#555599\",\"#995555\"])\n",
    "                \n",
    "tris2 = lv.triangles(\"triangles\",  wireframe=False, colour=\"#77ff88\", opacity=0.5)\n",
    "tris2.vertices(trianglesI.points * (1.0+0.000003*meshheights.reshape(-1,1)))\n",
    "tris2.indices(trianglesI.simplices)\n",
    "tris2.values(meshheights*0.001)\n",
    "tris2.colourmap([\"(-5.0)#555555\", \"(-0.001)#FFFFFF\", \"(0.0)#779977\", \"(0.1)#99AA99\", \"(1.0)#BBDDBB\", \"(5.0)#EEFFEE\"] , logscale=False, range=[-7.0,5.0])   # Apply a built in colourmap\n",
    "\n",
    "nodes = lv.points(\"DataPoints\", pointsize=5.0, pointtype=\"shiny\", colour=\"#448080\", opacity=0.75)\n",
    "nodes.vertices(data_xyz*1.01)\n",
    "nodes.values(data)\n",
    "nodes.colourmap([\"Blue\",\"Red\"])\n",
    "\n",
    "lv.window()\n",
    "\n",
    "tris.control.Checkbox(property='wireframe', label=\"Core - wireframe\")\n",
    "tris2.control.Checkbox(property='wireframe', label=\"Surface - wireframe\")\n",
    "tris3.control.Checkbox(property='wireframe', label=\"Data - wireframe\")\n",
    "\n",
    "\n",
    "# tris2.control.show()\n",
    "\n",
    "lv.control.Range('specular', range=(0,1), step=0.1, value=0)\n",
    "lv.control.Checkbox(property='axis')\n",
    "lv.control.ObjectList()\n",
    "lv.control.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c207b8ff0976>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c207b8ff0976>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print nodes.max()\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def weighted_average_to_nodes(lons, lats, data, interpolator ):\n",
    "\n",
    "    grid   = np.zeros(interpolator.npoints)\n",
    "    norm   = np.zeros(interpolator.npoints)\n",
    "    count  = np.zeros(interpolator.npoints, dtype=np.int)\n",
    "\n",
    "    bcc, nodes = interpolator.containing_simplex_and_bcc(lons, lats)\n",
    "    \n",
    "    print nodes.max()\n",
    "\n",
    "    # Beware vectorising the reduction operation !!\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "\n",
    "        grid[nodes[i][0]] += bcc[i][0] * data[i]\n",
    "        grid[nodes[i][1]] += bcc[i][1] * data[i]\n",
    "        grid[nodes[i][2]] += bcc[i][2] * data[i]\n",
    "\n",
    "        norm[nodes[i][0]] += bcc[i][0]\n",
    "        norm[nodes[i][1]] += bcc[i][1]\n",
    "        norm[nodes[i][2]] += bcc[i][2]\n",
    "        \n",
    "        count[nodes[i][0]] += 1\n",
    "        count[nodes[i][1]] += 1\n",
    "        count[nodes[i][2]] += 1\n",
    "        \n",
    "\n",
    "    grid[np.where(norm > 0.0)] /= norm[np.where(norm > 0.0)]\n",
    "    \n",
    "    return grid, norm, count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grids = [grid0]\n",
    "\n",
    "ave, norm, count = weighted_average_to_nodes(np.radians(lons), np.radians(lats), data, grids[-1])\n",
    "\n",
    "node_area = np.zeros(grids[-1].npoints)\n",
    "t_areas = grids[-1].areas()\n",
    "\n",
    "for t,simplex in enumerate(grids[-1].simplices):\n",
    "    node_area[simplex] += t_areas[t] \n",
    "\n",
    "node_area /= node_area.max()\n",
    "\n",
    "\n",
    "node_area.min()\n",
    "\n",
    "vertices = np.where(np.logical_and(norm > 10.0, node_area > 0.001))[0]\n",
    "\n",
    "print node_area.shape\n",
    "print norm.shape\n",
    "np.where(np.logical_and(norm > 10.0, node_area > 0.0001))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [grid0]\n",
    "\n",
    "for i in range(0, 20):\n",
    "\n",
    "    ave, norm, count = weighted_average_to_nodes(np.radians(lons), np.radians(lats), data, grids[-1])\n",
    "    \n",
    "    node_area = np.zeros(grids[-1].npoints)\n",
    "    t_areas = grids[-1].areas()\n",
    "\n",
    "    for t,simplex in enumerate(grids[-1].simplices):\n",
    "        node_area[simplex] += t_areas[t] \n",
    "  \n",
    "    node_area /= node_area.max()\n",
    "    \n",
    "    vertices = np.where(np.logical_and(norm > 10.0, node_area > 0.001))[0]\n",
    "\n",
    "    print vertices.shape[0], norm.min(), norm.max(), count.min(), count.max(), node_area.min()\n",
    "    \n",
    "    if vertices.shape[0] == 0:\n",
    "        break\n",
    "\n",
    "    newlons, newlats = grids[-1].edge_refine_triangulation_by_vertices(vertices=vertices)\n",
    "    rgrid = stripy.sTriangulation(newlons, newlats)\n",
    "    print newlons.shape[0], rgrid.npoints\n",
    "    grids.append(rgrid)\n",
    "\n",
    "\n",
    "ave_data, norm, count = weighted_average_to_nodes(np.radians(lons), np.radians(lats), data, grids[-1])\n",
    "\n",
    "## limit the minimum area\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tgrids = [grid0]\n",
    "\n",
    "for i in range(0, 20):\n",
    "    triangles = tgrids[-1].containing_triangle(np.radians(lons),np.radians(lats))\n",
    "    tcount = np.bincount(triangles)\n",
    "    t2refine = np.where(tcount > 10)[0]\n",
    "\n",
    "    print t2refine.shape[0], tcount.min(), tcount.max()\n",
    "    \n",
    "    if t2refine.shape == 0:\n",
    "        break\n",
    "\n",
    "    newlons, newlats = tgrids[-1].centroid_refine_triangulation_by_triangles(triangles=t2refine)\n",
    "    rgrid = stripy.sTriangulation(newlons, newlats)\n",
    "    tgrids.append(rgrid)\n",
    "\n",
    "\n",
    "t_ave_data, t_norm, count = weighted_average_to_nodes(np.radians(lons), np.radians(lats), data, tgrids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes where norm == 0 need to be interpolated ... \n",
    "\n",
    "zero_points = np.where(norm == 0.0)\n",
    "\n",
    "lons1 = grids[-1].lons[zero_points]\n",
    "lats1 = grids[-1].lats[zero_points]\n",
    "\n",
    "\n",
    "fixed_points, error_codes = datagrid.interpolate(lons1, lats1, data,order=1)\n",
    "\n",
    "ave_data[zero_points] = fixed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lavavu\n",
    "\n",
    "striangulationR = grids[-1]\n",
    "striangulation0 = grids[2]\n",
    "\n",
    "wireframeI = striangulationR\n",
    "trianglesI = gridR\n",
    "\n",
    "refined_data = ave_data\n",
    "\n",
    "opacity = norm / norm.max()\n",
    "\n",
    "lv = lavavu.Viewer(border=False, background=\"#FFFFFF\", resolution=[1000,1000], near=-10.0)\n",
    "\n",
    "# Core \n",
    "\n",
    "tris = lv.triangles(\"LAB\",  wireframe=False, colour=\"#999999\", opacity=1.0)\n",
    "tris.vertices(striangulation0.points * 0.95 )\n",
    "tris.indices(striangulation0.simplices)\n",
    "\n",
    "tris3 = lv.triangles(\"datagrid\",  wireframe=True, colour=\"#77ff88\", opacity=1.0)\n",
    "tris3.vertices(striangulationR.points)\n",
    "tris3.indices(striangulationR.simplices)\n",
    "tris3.values(ave_data, label=\"data\")\n",
    "tris3.colourmap([\"#555599 #995555\"])\n",
    "\n",
    "tris2 = lv.triangles(\"triangles\",  wireframe=False, colour=\"#77ff88\", opacity=0.5)\n",
    "tris2.vertices(trianglesI.points * (1.0+0.000003*meshheights.reshape(-1,1)))\n",
    "tris2.indices(trianglesI.simplices)\n",
    "tris2.values(meshheights*0.001, label=\"height\")\n",
    "tris2.colourmap([\"(-5.0)rgba(0.5,0.5,0.5,0) (-0.001)#FFFFFF (0.0)#779977 (0.1)#99AA99 (1.0)#BBDDBB (5.0)#EEFFEE\"] , logscale=False, range=[-7.0,5.0])   # Apply a built in colourmap\n",
    "\n",
    "# tris2.colourmap([\"Green Blue\"] ,  monochrome=False)   # Apply a built in colourmap\n",
    "\n",
    "\n",
    "nodes = lv.points(\"DataPoints\", pointsize=1.0, pointtype=\"shiny\", colour=\"#448080\", opacity=0.75)\n",
    "nodes.vertices(data_xyz*1.001)\n",
    "nodes.values(data)\n",
    "nodes.colourmap([\"#00FF00 #FF0000\"])\n",
    "\n",
    "tris.control.Checkbox(property='wireframe', label=\"Core - wireframe\")\n",
    "tris2.control.Checkbox(property='wireframe', label=\"Surface - wireframe\")\n",
    "tris3.control.Checkbox(property='wireframe', label=\"Data - wireframe\")\n",
    "\n",
    "# tris2.control.show()\n",
    "\n",
    "lv.control.Panel()\n",
    "lv.control.Range('specular', range=(0,1), step=0.1, value=0)\n",
    "lv.control.Checkbox(property='axis')\n",
    "lv.control.ObjectList()\n",
    "lv.control.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1bc65844a25b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstriangulationR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrefined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mave_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msmooth_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstriangulationR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefined_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grids' is not defined"
     ]
    }
   ],
   "source": [
    "striangulationR = grids[-1]\n",
    "refined_data = ave_data\n",
    "weights = 0.01 + norm / norm.max()\n",
    "\n",
    "smooth_d, deriv = striangulationR.smoothing(refined_data, weights, 10.0, 0.5, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.shape, grids[-1].npoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "99=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a base mesh that we will refine later\n",
    "\n",
    "mesh = stripy.spherical_meshes.icosahedral_mesh(refinement_levels=1, include_face_points=True)\n",
    "\n",
    "print \"Size of mesh - 1 \", mesh.npoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "global_extent     = [-180.0, 180.0, -90.0, 90.0]\n",
    "\n",
    "projection1 = ccrs.Orthographic(central_longitude=0.0, central_latitude=30, globe=None)\n",
    "projection2 = ccrs.Mollweide(central_longitude=-120)\n",
    "projection3 = ccrs.PlateCarree()\n",
    "base_projection = ccrs.PlateCarree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_map = np.isnan(te_data)\n",
    "# valid_point = np.empty(te_data.shape[0])\n",
    "\n",
    "# for i in range(0,len(valid_point)):\n",
    "#     valid_point[i] = np.logical_not(np.any( valid_map[i,:] ))\n",
    "     \n",
    "# print np.count_nonzero(valid_point), \" points are valid\"\n",
    "\n",
    "# lons = te_data[np.where(valid_point),0].reshape(-1)\n",
    "# lats = te_data[np.where(valid_point),1].reshape(-1)\n",
    "# te   = te_data[np.where(valid_point),2].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Background image\n",
    "\n",
    "globaletopo = gdal.Open(\"/Users/lmoresi/Dropbox/+Research/Publications/MyPapers/CooperMiller-ContinentalStructure/Data/ETOPO1_Ice_g_geotiff.tif\")\n",
    "\n",
    "\n",
    "globaletopo_img   = globaletopo.ReadAsArray()[::30,::30]\n",
    "del globaletopo\n",
    "\n",
    "from matplotlib.colors import LightSource, Normalize\n",
    "\n",
    "cmap=plt.cm.Greys\n",
    "ls = LightSource(315, 45)\n",
    "hillshade = ls.shade(globaletopo_img, cmap, vert_exag=0.00025)[1::,1::]\n",
    "\n",
    "## Drop one point here because the data are 361 x 721 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,12), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=projection3)\n",
    "ax.coastlines()\n",
    "ax.set_extent([-140.0,-70.0,20.0,80.0])\n",
    "ax.set_global()\n",
    "\n",
    "ax.imshow(hillshade, origin='upper', transform=base_projection, extent=global_extent, zorder=0)\n",
    "\n",
    "\n",
    "colormap = plt.cm.get_cmap('Spectral', 11)\n",
    "norm = colors.Normalize(vmin=0, vmax=200, clip=True)\n",
    "\n",
    "m = ax.scatter(lons, lats, c=te, cmap=colormap, vmin=0, vmax=70, # , norm=norm,\n",
    "               marker=\"o\", s=5.0, transform=ccrs.Geodetic(), \n",
    "               linewidth=0.0, alpha=1.0)\n",
    "\n",
    "fig.colorbar(mappable=m, orientation=\"horizontal\", shrink=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-dd1093dd6f35>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-dd1093dd6f35>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print \"Adding \", len(points[0]), \" to triangulation (\", interpolator.npts,\" )\"\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tegrid, tenorm, tecount  = weighted_average_to_nodes(lons, lats, te, interpolator )\n",
    "\n",
    "nodes_to_refine = np.where(tenorm > 10)[0] + 1\n",
    "\n",
    "points = subdivide_node_list(nodes_to_refine, interpolator)\n",
    "\n",
    "print \"Adding \", len(points[0]), \" to triangulation (\", interpolator.npts,\" )\"\n",
    "\n",
    "lonv2 = np.concatenate((interpolator.lons, points[0]), axis=0)\n",
    "latv2 = np.concatenate((interpolator.lats, points[1]), axis=0)\n",
    "\n",
    "interpolator1x = stripack.trmesh(lonv2, latv2)\n",
    "\n",
    "tegrid1x, tenorm1x, tecount1x  = weighted_average_to_nodes(lons, lats, te, interpolator1x )\n",
    "\n",
    "nodes_to_refine = np.where(tenorm1x > 10)[0] + 1\n",
    "\n",
    "points = subdivide_node_list(nodes_to_refine, interpolator1x)\n",
    "\n",
    "print \"Adding \", len(points[0]), \" to triangulation (\", interpolator1x.npts,\" )\"\n",
    "\n",
    "lonv2 = np.concatenate((interpolator1x.lons, points[0]), axis=0)\n",
    "latv2 = np.concatenate((interpolator1x.lats, points[1]), axis=0)\n",
    "\n",
    "interpolator2x = stripack.trmesh(lonv2, latv2)\n",
    "\n",
    "tegrid2x, tenorm2x, tecount2x  = weighted_average_to_nodes(lons, lats, te, interpolator2x )\n",
    "\n",
    "\n",
    "nodes_to_refine = np.where(tenorm2x > 10)[0] + 1\n",
    "\n",
    "points = subdivide_node_list(nodes_to_refine, interpolator2x)\n",
    "\n",
    "print \"Adding \", len(points[0]), \" to triangulation (\", interpolator2x.npts,\" )\"\n",
    "\n",
    "lonv2 = np.concatenate((interpolator2x.lons, points[0]), axis=0)\n",
    "latv2 = np.concatenate((interpolator2x.lats, points[1]), axis=0)\n",
    "\n",
    "interpolator3x = stripack.trmesh(lonv2, latv2)\n",
    "\n",
    "tegrid3x, tenorm3x, tecount3x  = weighted_average_to_nodes(lons, lats, te, interpolator3x )\n",
    "\n",
    "nodes_to_refine = np.where(tenorm3x > 10)[0] + 1\n",
    "\n",
    "points = subdivide_node_list(nodes_to_refine, interpolator3x)\n",
    "\n",
    "print \"Adding \", len(points[0]), \" to triangulation (\", interpolator3x.npts,\" )\"\n",
    "\n",
    "lonv2 = np.concatenate((interpolator3x.lons, points[0]), axis=0)\n",
    "latv2 = np.concatenate((interpolator3x.lats, points[1]), axis=0)\n",
    "\n",
    "interpolator4x = stripack.trmesh(lonv2, latv2)\n",
    "\n",
    "tegrid4x, tenorm4x, tecount4x  = weighted_average_to_nodes(lons, lats, te, interpolator4x )\n",
    "\n",
    "\n",
    "nodes_to_refine = np.where(tenorm4x > 10)[0] + 1\n",
    "\n",
    "points = subdivide_node_list(nodes_to_refine, interpolator4x)\n",
    "\n",
    "print \"Adding \", len(points[0]), \" to triangulation (\", interpolator4x.npts,\" )\"\n",
    "\n",
    "lonv2 = np.concatenate((interpolator4x.lons, points[0]), axis=0)\n",
    "latv2 = np.concatenate((interpolator4x.lats, points[1]), axis=0)\n",
    "\n",
    "interpolator5x = stripack.trmesh(lonv2, latv2)\n",
    "\n",
    "tegrid5x, tenorm5x, tecount5x  = weighted_average_to_nodes(lons, lats, te, interpolator5x )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntri, triangles5x = interpolator5x.tri_list()\n",
    "\n",
    "node_area = np.zeros(interpolator5x.npts)\n",
    "\n",
    "for tri in triangles5x.T:\n",
    "    tri_area = interpolator5x.tri_area(tri)\n",
    "    node_area[tri-1] += 0.333 * tri_area\n",
    "    \n",
    "# This is a measure of accuracy based on the distance between nodes ...     \n",
    "    \n",
    "weight = np.log(1.0 / (node_area))\n",
    "weight = weight / weight.max()\n",
    "weight.min(), weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interpolator = interpolator5x\n",
    "plot_hfgrid = tegrid5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick look to see what we got !\n",
    "\n",
    "\n",
    "global_extent = [-180.0, 180.0, -90.0, 90.0]\n",
    "\n",
    "projection1 = ccrs.Orthographic(central_longitude=0.0, central_latitude=80, globe=None)\n",
    "projection2 = ccrs.Mollweide(central_longitude=-120)\n",
    "projection3 = ccrs.PlateCarree()\n",
    "base_projection = ccrs.PlateCarree()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Robinson())\n",
    "ax.coastlines()\n",
    "ax.set_global()\n",
    "\n",
    "plons = np.degrees(plot_interpolator.lons)\n",
    "plats = np.degrees(plot_interpolator.lats)\n",
    "\n",
    "ax.scatter(plons, plats, c=plot_hfgrid, cmap=\"Spectral\", vmin=0.0, vmax=80.0,\n",
    "            marker=\"o\", s=10000*node_area, transform=ccrs.Geodetic(), linewidth=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridlonv, gridlatv = np.meshgrid(np.linspace(-180,180,720), np.linspace(90,-90,360), sparse=False, indexing='xy')\n",
    "gridlonv = gridlonv.reshape(-1)\n",
    "gridlatv = gridlatv.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolator = interpolator5x\n",
    "\n",
    "hfllgrid = interpolator.interp( np.radians(gridlonv), np.radians(gridlatv), tegrid5x, order=1)\n",
    "hfllnorm = interpolator.interp( np.radians(gridlonv), np.radians(gridlatv), weight, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.Mollweide(central_longitude=0)\n",
    "\n",
    "fig = plt.figure(figsize=(24,12), facecolor=\"none\", edgecolor=\"Black\", frameon=True)\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "\n",
    "ax.coastlines(linewidth=2.0)\n",
    "ax.set_extent([-140.0,-70.0,20.0,80.0])\n",
    "ax.set_global()\n",
    "\n",
    "colormap = plt.cm.get_cmap('Spectral')\n",
    "norm = colors.Normalize(vmin=0.0, vmax=50.0, clip=False)\n",
    "col  = colormap(norm(hfllgrid))\n",
    "\n",
    "## Now lighten the colors to represent areas with no coverage\n",
    "\n",
    "alpha = 0.05 + 0.95 * ((hfllnorm-hfllnorm.min()) / (hfllnorm.max()-hfllnorm.min()))\n",
    "# alpha = alpha**0.5\n",
    "\n",
    "col[:,0] = alpha[:] * col[:,0] + (1.0-alpha[:])\n",
    "col[:,1] = alpha[:] * col[:,1] + (1.0-alpha[:])\n",
    "col[:,2] = alpha[:] * col[:,2] + (1.0-alpha[:])\n",
    "\n",
    "# Apply hillshade image (works if gray cmap is used ... )\n",
    "\n",
    "col2 = col.reshape(360,720,4)**2 * (0.0 + 1.0 * hillshade)\n",
    "\n",
    "ax.imshow(col2, origin='upper', transform=base_projection,\n",
    "          extent=global_extent, zorder=2,  \n",
    "          interpolation=\"gaussian\")\n",
    "\n",
    "\n",
    "\n",
    "ax.add_feature(cartopy.feature.OCEAN, alpha=0.5, zorder=99, facecolor=\"#EEEEFE\")\n",
    "ax.coastlines(resolution=\"50m\", zorder=100)\n",
    "\n",
    "# ????? \n",
    "# cb1 = colorbar.ColorbarBase(ax, cmap=colormap,\n",
    "#                                 norm=norm,\n",
    "#                                 orientation='horizontal')\n",
    "\n",
    "# fig.savefig(\"ContinentalHeatFlow5x.png\", dpi=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
