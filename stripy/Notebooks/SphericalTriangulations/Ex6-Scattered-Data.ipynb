{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6 - Scattered Data and 'Heat Maps'\n",
    "\n",
    "There are different ways to map point data to a smooth field. One way is to triangulate the data, smooth it and interpolate to a regular mesh (see previous notebooks). It is also possible to construct weighted averages from scattered points to a regular mesh. In this notebook we work through how to find where points lie in the mesh and map their values to nearby vertices. \n",
    "\n",
    "#### Notebook contents\n",
    "\n",
    "   - [Computational mesh](#Define-a-regular-computational-mesh)\n",
    "   - [Scattered data](#Point-data-with-uneven-spatial-distribution)\n",
    "   - [Data count by triangle](#Count-earthquakes-per-triangle)\n",
    "   - [Data count by nearest vertex](#Count-earthquakes-per-vertex)\n",
    "   - [Distance weighting to vertices](#Inverse-distance-weighted-number-of-earthquakes)\n",
    "   - [Visualisation](#Visualisation)\n",
    "   \n",
    "   \n",
    "The next example is [Ex7-Refinement-of-Triangulations](./Ex7-Refinement-of-Triangulations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a regular computational mesh\n",
    "\n",
    "Use the (usual) icosahedron with face points included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stripy as stripy\n",
    "\n",
    "mesh = stripy.spherical_meshes.icosahedral_mesh(refinement_levels=5, include_face_points=True, tree=True)\n",
    "\n",
    "print(mesh.npoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point data with uneven spatial distribution\n",
    "\n",
    "Define a relatively smooth function that we can interpolate from the coarse mesh to the fine mesh and analyse. As it is a familiar pattern, we use the seismic event catalogue for M5.5+ (dawn of time to 2017-12-31) from IRIS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Note - these data have some places where depth is unknown (appears as NaN in the depth )\n",
    "# The IRIS data has  lat, lon, depth, mag  ... date/time in col 2, 3, 4, 10 (starting from zero)\n",
    "\n",
    "eqs = np.genfromtxt(\"../Data/EQ-M5.5-IRIS-ALL.txt\", usecols=(2,3,4,10), delimiter='|', comments=\"#\")    \n",
    "        \n",
    "\n",
    "lons = np.radians(eqs[:,1])\n",
    "lats = np.radians(eqs[:,0])\n",
    "depths = eqs[:,2]\n",
    "depths[np.isnan(depths)] = -1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gdal\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"#777777\" )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(lons)\n",
    "lats0 = np.degrees(lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=10.0, alpha=0.5, \n",
    "            transform=ccrs.Geodetic(), c=depths, cmap=plt.cm.RdBu)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count earthquakes per triangle \n",
    "\n",
    "This is a numpy wrapper around the `STRIPACK` routine which operates by retriangulation and is therefore not particularly fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = mesh.containing_triangle(lons, lats)\n",
    "tris, counts = np.unique(triangles, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map to nodes so we can plot this\n",
    "\n",
    "hit_count = np.zeros_like(mesh.lons)\n",
    "\n",
    "for i in range(0, tris.shape[0]):\n",
    "    hit_count[mesh.simplices[tris[i]]] += counts[i]\n",
    "\n",
    "hit_count /= 3.0\n",
    "\n",
    "print(hit_count.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=30.0, transform=ccrs.Geodetic(), c=hit_count, cmap=plt.cm.Reds, vmin=0.333, vmax=20.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count earthquakes per vertex\n",
    "\n",
    "The `sTriangulation.nearest_vertices` method uses a k-d tree to find the nearest vertices to a set of longitude / latitude points. It returns the great circle distance. This requires the k-d tree to have been built when the mesh was initialised (`tree=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, vertices = mesh.nearest_vertices(lons, lats, k=1)\n",
    "nodes, ncounts = np.unique(vertices, return_counts=True)\n",
    "\n",
    "hit_countn = np.zeros_like(mesh.lons)\n",
    "hit_countn[nodes] = ncounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=30.0, transform=ccrs.Geodetic(), c=hit_countn, cmap=plt.cm.Reds, vmin=0.333, vmax=10.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse distance weighted number of earthquakes\n",
    "\n",
    "The k-d tree method provides a specified number of neighbours and the arc lengths to those neighbours. This can be used in a number of ways to smooth or amalgamate data. Here for example is a weighted average of each earthquake to nearby nodes. \n",
    "\n",
    "We compute the distances to $N$ nearby vertices and distribute information to those vertices in inverse proportion to their distance.\n",
    "\n",
    "$$ w _i = \\frac{d _i}{\\sum_{i=1}^N d _i} $$\n",
    "\n",
    "Alternatively, we might map information to the vertices by applying a radially symmetric kernel to the point data without normalising.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, vertices = mesh.nearest_vertices(lons, lats, k=10)\n",
    "norm = distances.sum(axis=1)\n",
    "\n",
    "# distances, vertices are arrays of shape (data_size, 10)\n",
    "\n",
    "hit_countid = np.zeros_like(mesh.lons)\n",
    "\n",
    "## numpy shouldn't try to vectorise this reduction operation\n",
    "\n",
    "for i in range(0,distances.shape[0]):\n",
    "    hit_countid[vertices[i,:]] += distances[i,:] / norm[i]\n",
    "\n",
    "\n",
    "hit_countidr = np.zeros_like(mesh.lons)\n",
    "\n",
    "## numpy shouldn't try to vectorise this reduction operation\n",
    "\n",
    "for i in range(0,distances.shape[0]):\n",
    "    hit_countidr[vertices[i,:]] += np.exp( -distances[i,:] / 0.02 ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", s=30.0, transform=ccrs.Geodetic(), c=hit_countid, cmap=plt.cm.Reds, vmin=0.333, vmax=10.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping data other than frequency to the regular mesh\n",
    "\n",
    "Here we show how to map point data to the regular mesh - produce a representation of the depth of the events instead of just their frequency. When plotting, we need to distinguish between zero information and zero (shallow) depth. This is done by using the weight function to determine the opacity of the symbol or field that we plot. This has the effect of washing out the regions with few, large events compared to those with many small ones (which in this case means washed out regions where earthquakes are deep). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_idr = np.zeros_like(mesh.lons)\n",
    "\n",
    "## numpy shouldn't try to vectorise this reduction operation\n",
    "\n",
    "for i in range(0,distances.shape[0]):\n",
    "    depth_idr[vertices[i,:]] += depths[i] * np.exp( -distances[i,:] / 0.02 ) \n",
    "\n",
    "depth_idr[hit_countidr != 0.0] /=  hit_countidr[hit_countidr != 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10), facecolor=\"none\")\n",
    "ax  = plt.subplot(111, projection=ccrs.Mollweide())\n",
    "ax.coastlines(color=\"lightgrey\", )\n",
    "ax.set_global()\n",
    "\n",
    "lons0 = np.degrees(mesh.lons)\n",
    "lats0 = np.degrees(mesh.lats)\n",
    "\n",
    "ax.scatter(lons0, lats0, \n",
    "            marker=\"o\", transform=ccrs.Geodetic(), c=depth_idr, s=hit_countidr,\n",
    "            cmap=plt.cm.RdBu, vmin=0.0, vmax=500.0, alpha=0.25)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lavavu\n",
    "\n",
    "\n",
    "depth_range = depths.max()\n",
    "\n",
    "lv = lavavu.Viewer(border=False, background=\"#FFFFFF\", resolution=[666,666], near=-10.0)\n",
    "\n",
    "\n",
    "tris = lv.triangles(\"triangles\",  wireframe=False, colour=\"#77ff88\", opacity=1.0)\n",
    "tris.vertices(mesh.points)\n",
    "tris.indices(mesh.simplices)\n",
    "\n",
    "tris.values(hit_count, label=\"hit_count\")\n",
    "tris.values(hit_countn, label=\"hit_countn\")\n",
    "tris.values(hit_countid, label=\"hit_countid\")\n",
    "tris.values(hit_countidr, label=\"hit_countidr\")\n",
    "tris.colourmap(\"#FFFFFF:0.0 (1.0)#FF0000:0.2 (50.0)#550044:0.5\")\n",
    "\n",
    "\n",
    "depth = lv.triangles(\"depth_field\",  wireframe=False, colour=\"#FFFFFF\", opacity=0.999)\n",
    "depth.vertices(mesh.points*(6370-depth_range*0.99) / 6370)\n",
    "depth.indices(mesh.simplices)\n",
    "depth.values(depth_idr, label=\"depths\")\n",
    "depth.values(hit_countidr/hit_countidr.max(), label=\"weights\")\n",
    "depth.colourmap(\"#550000 #0099FF #000055\")\n",
    "\n",
    "depth[\"opacitymap\"] = \"#000000:0.0 (0.1)#000000:0.9 #000000:0.9\"\n",
    "depth[\"opacityby\"] = \"weights\"\n",
    "depth[\"colourby\"]  = \"depths\"\n",
    " \n",
    "bg = lv.triangles(\"background\",  wireframe=False, colour=\"#FFFFFF\", opacity=1.0)\n",
    "bg.vertices(mesh.points*(6370-depth_range) / 6370)\n",
    "bg.indices(mesh.simplices)\n",
    "\n",
    "ll = np.array(stripy.spherical.lonlat2xyz(lons, lats)).T\n",
    "\n",
    "nodes = lv.points(\"events\", pointsize=3.0, pointtype=\"shiny\", colour=\"#448080\", opacity=0.75)\n",
    "nodes.vertices(ll * (6370.0 - depths.reshape(-1,1)) / 6370.0 )\n",
    "nodes.values(depths, label=\"depths\")\n",
    "nodes.colourmap(\"#550000 #0099FF #000055\")\n",
    "\n",
    "# View from the pacific hemisphere \n",
    "lv.translation(0.0, 0.0, -3.0)\n",
    "lv.rotation(0.0,90.0, 90.0)\n",
    "\n",
    "\n",
    "lv.control.Panel()\n",
    "lv.control.Range('specular', range=(0,1), step=0.1, value=0.4)\n",
    "lv.control.Checkbox(property='axis')\n",
    "lv.control.ObjectList()\n",
    "tris.control.List([\"hit_count\", \"hit_countn\", \"hit_countid\", \"hit_countidr\"], property=\"colourby\", value=\"hit_count\", command=\"redraw\")\n",
    "lv.control.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example is [Ex7-Refinement-of-Triangulations](./Ex7-Refinement-of-Triangulations.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
